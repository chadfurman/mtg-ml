{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Card vectorization\n",
    "## Introduction\n",
    "In this notebook we will:\n",
    "1. Grab parsed oracle text for cards\n",
    "2. vectorize oracle text using word2vec \n",
    "3. train XGBoost on the vecorizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "1. Use requirements.txt to install dependencies\n",
    "2. Execute `python -m spacy download en_core_web_sm` on the command line to install the English language module \n",
    "3. Setup the database following the instructions in the readme\n",
    "4. Run `python mtg-ml.py preprocess` to parse cards in the db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Notebook Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported modules successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src/') # needed for nlp import\n",
    "\n",
    "import psycopg2, re, string, gzip\n",
    "from numpy import array, mean\n",
    "from numpy.random import choice\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from nlp.oracle_text_parser import OracleTextParser\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "from random import shuffle\n",
    "import pprint\n",
    "\n",
    "print(\"Imported modules successfully\")\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "We query the database directly, assuming it was already populated and preprocessed.\n",
    "We are only working on a subset of all MTG cards which are legal in all types and also which are english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cards in our dataset: 28265\n",
      "[{'cost': \"{'red': 0, 'blue': 0, 'black': 0, 'green': 0, 'white': 0, \"\n",
      "          \"'colorless': 0, 'generic': 0, 'life': False, 'discard': False, \"\n",
      "          \"'loyalty': False, 'sacrifice': False, 'hybrid': False, 'tap': \"\n",
      "          \"False, 'untap': False}\",\n",
      "  'effect': \"{'bigrams': [], 'effect': Indestructible, 'tokens': \"\n",
      "            \"['Indestructible'], 'nouns': [], 'verbs': [], 'phrases': []}\",\n",
      "  'name': 'Athreos, Shroud-Veiled'},\n",
      " {'cost': \"{'red': 0, 'blue': 0, 'black': 0, 'green': 0, 'white': 0, \"\n",
      "          \"'colorless': 0, 'generic': 0, 'life': False, 'discard': False, \"\n",
      "          \"'loyalty': False, 'sacrifice': False, 'hybrid': False, 'tap': \"\n",
      "          \"False, 'untap': False}\",\n",
      "  'effect': \"{'bigrams': ['As long', 'long devotion', 'devotion to', 'to \"\n",
      "            \"white', 'white black', 'black less', 'less Athreos', 'Athreos \"\n",
      "            \"creature'], 'effect': As long as your devotion to white and black \"\n",
      "            \"is less than seven, Athreos isn't a creature., 'tokens': ['As', \"\n",
      "            \"'long', 'as', 'your', 'devotion', 'to', 'white', 'and', 'black', \"\n",
      "            \"'is', 'less', 'than', 'seven', ',', 'Athreos', 'is', \"\n",
      "            '\"n\\'t\", \\'a\\', \\'creature\\', \\'.\\'], \\'nouns\\': [\\'devotion\\', '\n",
      "            \"'Athreos', 'creature'], 'verbs': [], 'phrases': ['your devotion', \"\n",
      "            \"'Athreos', 'a creature']}\",\n",
      "  'name': 'Athreos, Shroud-Veiled'},\n",
      " {'cost': \"{'red': 0, 'blue': 0, 'black': 0, 'green': 0, 'white': 0, \"\n",
      "          \"'colorless': 0, 'generic': 0, 'life': False, 'discard': False, \"\n",
      "          \"'loyalty': False, 'sacrifice': False, 'hybrid': False, 'tap': \"\n",
      "          \"False, 'untap': False}\",\n",
      "  'effect': \"{'bigrams': ['At beginning', 'beginning of', 'of end', 'end \"\n",
      "            \"step', 'step put', 'put coin', 'coin counter', 'counter on', 'on \"\n",
      "            \"target', 'target creature'], 'effect': At the beginning of your \"\n",
      "            'end step, put a coin counter on another target creature., '\n",
      "            \"'tokens': ['At', 'the', 'beginning', 'of', 'your', 'end', 'step', \"\n",
      "            \"',', 'put', 'a', 'coin', 'counter', 'on', 'another', 'target', \"\n",
      "            \"'creature', '.'], 'nouns': ['beginning', 'end', 'step', 'coin', \"\n",
      "            \"'counter', 'target', 'creature'], 'verbs': ['put'], 'phrases': \"\n",
      "            \"['the beginning', 'your end step', 'a coin counter', 'another \"\n",
      "            \"target creature']}\",\n",
      "  'name': 'Athreos, Shroud-Veiled'},\n",
      " {'cost': \"{'red': 0, 'blue': 0, 'black': 0, 'green': 0, 'white': 0, \"\n",
      "          \"'colorless': 0, 'generic': 0, 'life': False, 'discard': False, \"\n",
      "          \"'loyalty': False, 'sacrifice': False, 'hybrid': False, 'tap': \"\n",
      "          \"False, 'untap': False}\",\n",
      "  'effect': \"{'bigrams': ['Whenever creature', 'creature with', 'with coin', \"\n",
      "            \"'coin counter', 'counter on', 'on dies', 'dies put', 'put into', \"\n",
      "            \"'into exile', 'exile return', 'return card', 'card to', 'to \"\n",
      "            \"battlefield', 'battlefield under', 'under control'], 'effect': \"\n",
      "            'Whenever a creature with a coin counter on it dies or is put into '\n",
      "            'exile, return that card to the battlefield under your control., '\n",
      "            \"'tokens': ['Whenever', 'a', 'creature', 'with', 'a', 'coin', \"\n",
      "            \"'counter', 'on', 'it', 'dies', 'or', 'is', 'put', 'into', \"\n",
      "            \"'exile', ',', 'return', 'that', 'card', 'to', 'the', \"\n",
      "            \"'battlefield', 'under', 'your', 'control', '.'], 'nouns': \"\n",
      "            \"['creature', 'coin', 'counter', 'exile', 'card', 'battlefield', \"\n",
      "            \"'control'], 'verbs': ['dies', 'put', 'return'], 'phrases': ['a \"\n",
      "            \"creature', 'a coin counter', 'it', 'exile', 'that card', 'the \"\n",
      "            \"battlefield', 'your control']}\",\n",
      "  'name': 'Athreos, Shroud-Veiled'}]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(database=\"mtg_local\", user=\"mtg\", password=\"mtg_pass\", port=5432, host='localhost')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# This pulls oracle_id, title, type, and actions (cost/effect pairs) for each card\n",
    "cur.execute(\"select cards.id, cards.name, actions.cost, actions.effect from cards, actions where exists( select 1 from jsonb_each_text(cards.legalities) j where j.value not like '%not_legal%') and lang='en' and cards.id = actions.card_id;\")\n",
    "card_actions = cur.fetchmany(-1)\n",
    "cards = {} \n",
    "for raw_action in card_actions:\n",
    "    id = raw_action[0]\n",
    "    name = raw_action[1]\n",
    "    cost = raw_action[2]\n",
    "    effect = raw_action[3]\n",
    "    card_action = { 'name': name, 'cost': cost, 'effect': effect }\n",
    "    if id not in cards.keys():\n",
    "        cards[id] = [card_action]\n",
    "    else:\n",
    "        cards[id].append(card_action)\n",
    "        \n",
    "    \n",
    "print(f\"Number of cards in our dataset: {len(cards)}\")\n",
    "for card_id in cards:\n",
    "    card = cards[card_id]\n",
    "    print(f\"{pp.pprint(card)}\")\n",
    "    break\n",
    "# done with db connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### joining the cards with their tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cards tagged with discard-outlet: 409\n",
      "Number of cards tagged with draw: 75\n",
      "Number of cards tagged with ramp: 641\n",
      "Number of cards tagged with removal: 1778\n",
      "Number of cards tagged with sacrifice-outlet: 156\n",
      "Number of cards tagged with sweeper: 495\n"
     ]
    }
   ],
   "source": [
    "PATH_TAGS = join(*['..', 'data', 'cards-tags'])\n",
    "\n",
    "oracleid2tag = {}\n",
    "for filename in listdir(PATH_TAGS):\n",
    "    tag_name = filename.split('.')[0]\n",
    "    tag_count = 0\n",
    "    with open(join(PATH_TAGS, filename), 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0:  # drop the first line of the file, because it just contains the header\n",
    "                continue\n",
    "            oracleid2tag[line[:-1]] = tag_name  # the last character in carriage return, remove\n",
    "            tag_count += 1\n",
    "    print(f\"Number of cards tagged with {tag_name}: {tag_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: how many total cards in our corpus have a tag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3425 of 46177 cards tagged\n"
     ]
    }
   ],
   "source": [
    "num_tagged_cards = len(set(oracleid2tag.keys()))\n",
    "print(f'{num_tagged_cards} of {len(cards)} cards tagged')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the preprocessed card data stored in the database, parsed out as cost and effect pairs for each action found in the oracle text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 0 cards so far...\n",
      "Preprocessed 100 cards so far...\n",
      "Preprocessed 200 cards so far...\n",
      "Preprocessed 300 cards so far...\n",
      "Preprocessed 400 cards so far...\n",
      "Preprocessed 500 cards so far...\n",
      "Preprocessed 600 cards so far...\n",
      "Preprocessed 700 cards so far...\n",
      "Preprocessed 800 cards so far...\n",
      "Preprocessed 900 cards so far...\n",
      "Preprocessed 1000 cards so far...\n",
      "Preprocessed 1100 cards so far...\n",
      "Preprocessed 1200 cards so far...\n",
      "Preprocessed 1300 cards so far...\n",
      "Preprocessed 1400 cards so far...\n",
      "Preprocessed 1500 cards so far...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d0553549d3a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Preprocessed {card_index} cards so far...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mpreprocessed_cards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-d0553549d3a3>\u001b[0m in \u001b[0;36mpreprocess_card\u001b[0;34m(card)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0moracle_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mOracleTextParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_oracle_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracle_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpreprocessed_cards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ml/mtg-ml/src/nlp/oracle_text_parser.py\u001b[0m in \u001b[0;36mparse_oracle_text\u001b[0;34m(raw_card_text)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_oracle_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_card_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# test_preprocessed_card_text_is_separated_into_actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0maction_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOracleTextParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_list_from_raw_card_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_card_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maction_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ml/mtg-ml/src/nlp/oracle_text_parser.py\u001b[0m in \u001b[0;36mget_action_list_from_raw_card_text\u001b[0;34m(raw_card_text)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_action_list_from_raw_card_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_card_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_card_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "preprocessed_cards = {}\n",
    "for card_index in range(len(cards)):\n",
    "    card = cards[card_index]\n",
    "    if card is None:\n",
    "        continue\n",
    "    if card_index % 100 == 0:\n",
    "        print(f\"Preprocessed {card_index} cards so far...\")\n",
    "    id = card[0]\n",
    "    card = preprocess_card(card)\n",
    "    preprocessed_cards[id] = card\n",
    "\n",
    "print(f\"Preprocessed {len(preprocessed_cards)} cards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "We will vectorize the cards through 3 distinct methods: bag of words, Tf-Idf and word2vec. For bag of words and tf-idf, the pipeline is roughly 1. train/test split, 2. fit on train 3. predict on test. For word2vec it's more free.\n",
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(preprocessed_cards.values())\n",
    "\n",
    "print(X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf\n",
    "Tf-Idf is applied on the bag of word vectorization computed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "\n",
    "print(X_train_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec\n",
    "*word2vec* is a method to represent words by vectors such that their cosine proximity reflects their semantic similarity (simpler: the closer the meaning of 2 words, the closer their vectors). There exists already files containing word2vec vectors for English words trained on large corpora. Here we will train a word2vec representation of the words in the cards based on the text in the cards. So we get a fully customized word2vec representation for *MGT*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = get_tmpfile(\"./data/word2vec.model\")\n",
    "\n",
    "model = Word2Vec(preprocessed_cards, size=100, window=5, min_count=1, workers=4)\n",
    "model.wv.save_word2vec_format(\"../../data/word2vec.txt\")\n",
    "\n",
    "# gzip the model\n",
    "f_in = open('../../data/word2vec.txt', 'rb')\n",
    "f_out = gzip.open('../../data/word2vec.txt.gz', 'wb')\n",
    "f_out.writelines(f_in)\n",
    "f_out.close()\n",
    "f_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create model by executing `python3.6 -m spacy init-model en ./data/spacy.word2vec.model --vectors-loc data/word2vec.txt.gz` on the command line.\n",
    "\n",
    "Result:\n",
    "\n",
    "```\n",
    "✔ Successfully created model\n",
    "33it [00:00, 15872.94it/s]a/word2vec.txt.gz\n",
    "✔ Loaded vectors from data/word2vec.txt.gz\n",
    "✔ Sucessfully compiled vocab\n",
    "499 entries, 33 vectors\n",
    "\n",
    "```\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And vectorize the cards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp_mtg = load('../../data/spacy.word2vec.model')\n",
    "card_vectors = []\n",
    "for preprocessed_card in preprocessed_cards:\n",
    "    card_vector = nlp_mtg(preprocessed_card)\n",
    "    card_vectors.append(card_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tag2label = {tag: i for i, tag in enumerate(list(set(oracleid2tag.values())))}\n",
    "\n",
    "X = [preprocessed_cards[card_id] for card_id in tagged_cards_id]\n",
    "y = [tag2label[oracleid2tag[card_id]] for card_id in tagged_cards_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a pipeline bag-of-words => tf-idf => classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit it on the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "perf = mean(predicted == y_test)\n",
    "\n",
    "print(f'{round(100 * perf, 2)}% of the cards in the test data correctly classified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the baseline (the performance if we classify the cards randomly)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = list(tag2label.values())\n",
    "random_perfs = []\n",
    "for _ in range(1000):\n",
    "    predicted_random = choice(labels, size=len(y_test))\n",
    "    random_perf = mean(predicted_random == y_test)\n",
    "    random_perfs.append(random_perf)\n",
    "random_baseline = mean(random_perfs)\n",
    "\n",
    "print(f'baseline: random performance: {round(100 * random_baseline, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "1. Train to tune the model in various ways (preprocess the cards with `all=False` or `all=True`, try systematically different hyperparemeters for the vectorizer, tf-idf, try different classifiers with different classifiers)\n",
    "2. Diagnostic: which cards are misclassified? Why?\n",
    "3. Try modelization with word2vec vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (mtg-ml)",
   "language": "python",
   "name": "pycharm-9d6de384"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
